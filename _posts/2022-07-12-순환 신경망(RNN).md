---
layout : single
title : '순환신경망 (RNN)'
categories: DeepLearning
toc: true
toc_sticky: true
---

# 순환 신경망(RNN)

##### 시퀀스표현

![](https://camo.githubusercontent.com/96d6121ed4e79057849d7c23866fb6c1e4061ba02d1ccf6edea4585d4e60e5a6/68747470733a2f2f6769742e696f2f4a4c64566d)

MLP나 CNN같이 일반 신경망 모델은 훈련 샘플이 서로 독립적이어서 순서 정보와 연관이 없다고 가정한다. 이와 대조적으로 **RNN**은 **시퀀스 모델링**을 위해 고안되었으며 과거 정보를 기억하고 이에 맞추어 새로운 샘플을 처리할 수 있다

##### 시퀀스 모델링

![](https://camo.githubusercontent.com/54e7410901be4a12012695e7842362c7f125ab26a5fbd286b02ded49f5ee8208/68747470733a2f2f6769742e696f2f4a4c64564f)

* **다대일(many-to-one)** : 입력 데이터가 시퀀스, 출력은 고정 크기의 벡터나 스칼라  /    예를들어 감성 분석에서 입력은 텍스트 / 출력은 클래스 레이블(좋아하는지)

* **일대다(one-to-many)** : 입력데이터가 시퀀스가 아니라 일반적인 형태 / 출력은 시퀀스     예를들어 이미지캡셔닝 : 입력이 이미지이고 출력은 이미지 내용을 요약한 문장

* **다대다(many-to-many)** : 입력과 출력이 모두 시퀀스
  
  * 동기적인 다대다 모델링 : 각 프레임을 레이블링하는 비디오 분류
  
  * 지연이 있는 다대다 모델링 : 한 언어에서 다른 언어로 번역하는 작업

##### RNN구조

![](https://camo.githubusercontent.com/48f1da4cc94f7c5cff7cbf4b13e6ab69f8b68ba533f28e5e658ce3b515c222c5/68747470733a2f2f6769742e696f2f4a4c645673)

* $t = 0$에서는 은닉 유닛이 0 또는 작은 난수로 초기화 된다.

* $t > 0$인 타임 스텝에서는 은닉 유닛이 현재 타임 스텝의 데이터 포인트 $x^t$와 이전 타임 스텝 $t-1$의 은닉 유닛 값 $h^{t-1}$을 입력으로 받는다

##### 활성화 출력

![](https://camo.githubusercontent.com/a3597f23bc47bb40ff85994fe0ef42decb8c02d4ec3387c6e214052841c13a20/68747470733a2f2f6769742e696f2f4a4c645643)

* **$W_{xh}$**: 입력 $x^t$와 은닉층 $h$사이의 가중치 행렬 

* **$W_{hh}$**:순환 에지에 연관된 가중치 행렬

* **$W_{ho}$**: 은닉층과 출력층 사이의 가중치 행렬

![](https://camo.githubusercontent.com/9d9950893993411a80594179bd608d10eb57e220501cba40714332cca79d5738/68747470733a2f2f6769742e696f2f4a4c645657)

###### $z_h^t$ : 활성화 함수를 통과하기 전의 값

* $z_h^t = W_{xh}x^t + W_{hh}h^{t-1} + b_h$

* $h^t = \sigma_h(z_h^t) = \sigma_h(W_{xh}x^t + W_{hh}h^{t-1} + b_h)$

* $o_t = \sigma_h(W_{ho}h^t + b_o)$


